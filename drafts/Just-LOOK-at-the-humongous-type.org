#+TITLE: Just LOOK at the humongous type that Hindley-Milner infers for this tiny program!
#+AUTHOR: aki

** Or, check out this one weird trick to make Hindley-Milner blow-up! Haskell compilers hate it!

Last month I gave a mini-talk at [[http://bangbangcon.com/][!!Con]], which was loads of fun! The
videos of all of the talks are online, so you can [[http://bangbangcon.com/recordings.html][watch them]] if you
weren't able to attend and haven't seen them yet.

My talk was on the worst case performance of Hindley-Milner type
inference. The punch-line is that in the worst case, the performance
is exponential in both time and space in the size of the program
source. I found this both interesting and baffling when I first
learned about it, since exponential time is, well, kind of bad.

This was my first talk ever. I submitted a proposal fully expecting it
to be rejected. Not only that, but I submitted a proposal with very
little material prepared. I had worked on an implementation of baby
Hindley-Milner (no let-polymorphism, which turns out to be relevant)
last summer at Hacker School, but all I knew about the performance was
that there exists this edge case, I really didn't understand why.

Perhaps as a result, the talk was a little rough around the edges!
While I certainly hope that some of the !!Con attendees got something
out of it, I wouldn't fault anyone for getting immediately lost after
the intro. Furthermore, I had to end the talk in a sort of
anticlimactic way because I hadn't yet fully wrapped my head around
the issue. Only afterward did the pieces really fall into place for
me.

I thought it would be helpful (for myself as much as anyone else) if I
wrote up the contents of the talk as a blog post and flesh out some of
the finer points.

** Haskell and ML

All of the examples in this post use Standard ML, but anywhere I say
"ML" you can imagine I'm talking about Haskell, OCaml, or F#, since at
least as far as the type inference algorithms are concerned, these
languages are similar. In actual fact, the papers that prove the
exponential time result boil things down to a core ML language which
is only a little bit richer than the lambda calculus.

If you're not familiar with Haskell or ML (or another statically typed
functional languages that uses Hindley-Milner) unfortunately this post
may be meaningless to you. At the beginning of my talk I tried to give
the audience a crash course on the syntax of the lambda calculus so
that everyone would at least be able to read my slides but I'm going
to skip that overview here, on the assumption that there are better
resources for learning about ML and the lambda calculus than a hasty
introduction written by me. [[http://www.cs.cmu.edu/~rwh/smlbook/book.pdf][This is a very good introductory book]] on
Standard ML, written by Robert Harper of CMU, which I highly recommend
if you're interested in learning ML. SML is (currently) my
Hindley-Milner language of choice, but Haskell is sometimes called the
crown-jewel of the Hindley-Milner family, for good reason, and there
are loads of high quality resources for learning Haskell.

** Hindley-Milner

For a long time, the performance of Hindley-Milner type inference was
thought to be [polymorphic? linear?] but this was largely a folklore
result, until a few different computer scientists proved that the
actual worst case performance was much slower.

I ran across this in [[http://stackoverflow.com/questions/22060592/very-long-type-inference-sml-trick][a Stack Overflow question (and answer)]], and
although that answer actually sums up everything in this post and in
my talk, I ended up having to research this quite a bit more since I
wasn't able to wrap my head around it with just the examples given
there. Most of my understanding I derived from the paper "Deciding ML
typability is complete for deterministic exponential time" published
by Harry G. Mairson in 1990. I've included a complete list of
references at the bottom of this post.

The crux of the issue is that there are two features of Hindley-Milner
type systems that work together to ruin the performance of the
algorithm. Both of them relate to `let` expressions, and in fact if
you take `let` away you can do type inference in linear time. That
fact alone is quite interesting to me, since while `let` is an
important feature of ML, it appears to be quite a costly one!

The two features involved in the pathological case are
let-polymorphism and the ability of `let` to express exponential
function composition. Together, they enable an ML programmer to write
programs which construct expressions whose types are actually
exponential in size. In fact, the main reason that this edge case is
not a problem in practice and that Hindley-Milner is "fast enough" is
that it's extraordinarily rare to have types this large in real
programs!

** let-polymorphism

The first feature of Hindley-Milner that I'll discuss is
"let-polymorphism", but before I get to it I should briefly review ML
style polymorphism. You may be familiar with this in Haskell or ML but
if not you might have encountered it in Java, C#, Scala and other
langauges in the form of "generics".

*** parametric polymorphism

Parametric polymorphism is a feature of a type system that enables
code reuse by introducing type variables that can range over any other
type. The simplest example of a polymorphic value is the identity
function (recall that this is Standard ML):

#+BEGIN_SRC sml
  fun id x = x
#+END_SRC

The type of this function is `'a -> 'a`, which means that it takes a
value any type, and returns a value of that same type (`->` is the
type constructor for functions). Without parametric polymorphism,
you'd have to write a version of the identity function for every
concrete type: one for integers, booleans, characters, strings,
etc. The same applies to more interesting functions like `map`:

#+BEGIN_SRC sml
  fun map f l = ...
#+END_SRC

The type of `map` is `('a -> 'b) -> 'a list -> 'b list` and it can be
used with lists containing values of any type, and functions mapping
that type to any other type (in ML, type constructors are postfix, so
`'a list` means "list of `'a`", a.k.a. `List<A>` in Java).

*** let vs lambda

There are two kinds of local variables in ML, let-bound variables
which are introduced by `let` and lambda-bound variables which are
arguments in a `lambda` expression, i.e. an anonymous function
expression. Arguments to named functions are considered the same as
lambda-bound variables, since function declarations can be treated as
syntactic sugar.

If `f` isn't recursive, then

#+BEGIN_SRC sml
  fun f x = ...
#+END_SRC

is the same as

#+BEGIN_SRC sml
  val f = fn x => ...
#+END_SRC

and if it is recursive it's the same as

#+BEGIN_SRC sml
  val rec f = fn x => ...
#+END_SRC

If you're coming from a Lisp or a Scheme, which is where I was before
learning ML, then you're probably familiar with this relationship
between `let` and `lambda`. When being first introduced to macros,
`let` is often an early example, because you can implement `let` as a
macro, in terms of `lambda` and function applications. For example:

#+BEGIN_SRC sml
  let
     val x = e
  in
     body
  end
#+END_SRC

would be transformed into

#+BEGIN_SRC sml
  (fn x => body) e
#+END_SRC

Both of these create a local variable named `x`, bind it to `e`, and
evaluate the `body`. JavaScript programmers call this second form an
immediately-invoked-function-expression, and it's a way to introduce
local variables due to the fact that JavaScript only has function
scope.

It turns out that there's a crucial difference with the way let-bound
and lambda-bound variables are typed in Hindley-Milner languages.

Here's an example of a program using `let`:

#+BEGIN_SRC sml
  let
     val id = fn x => x
  in
     (id 3, id true)
  end
#+END_SRC

It introduces a polymorphic identity function, binds it to `id`, and
then calls it with `3` and `true`. This type checks under
Hindley-Milner without any problem.

Now here's the same example if you transformed it as if `let` was a macro:

#+BEGIN_SRC sml
  (fn id => (id 3, id true)) (fn x => x)
#+END_SRC

In this case, the function on the left is being applied to an
anonymous identity function, binding it to `id` and calling it with
`3` and `true` again. This doesn't type check under Hindley-Milner.

The reason that this program doesn't type check but the previous one
does is that lambda-bound variables are not allowed to have
polymorphic values, but let-bound variables are.

So in ML, `let` is more than syntactic sugar, and this feature is
called "let-polymorphism".

One way that `let-polymorphism` could be implemented in a type checker
is to literally copy and paste the code. In the example above the
compiler would generate an integer and a boolean version of the
identity function and apply them to the right arguments in the
body. Of course, there are other ways to implement it, but naive
approach hints at the complications it introduces.

** exponential function composition

The second feature of ML that conspires to degrade the performance of
Hindley-Milner is something that just sort of falls out from the way
that `let` works. It allows us to concisely express exponential
function composition. In essence, `let` allows us to write a series of
increasingly larger programs which only grow in size linearly, but
consist of composing a function an exponential number of times.

As an example, here's a little ML program that uses `let`:

#+BEGIN_SRC sml
  let val x0 = fn x => x in
     let val x1 = fn y => x0(x0(y)) in
        x1
     end
  end
#+END_SRC

The first `let` binds `x0` to the familiar identity function: `fn x =>
x`. The second `let` binds `x1` to a function that composes `x0`
twice. The body of the these nested `let`s returns `x1` which actually
behaves the same as the identity function. Leaving aside that this
program does't do anything very interesting for a moment, here's
another program with nested `let`s, that's got one extra level of
nesting:

#+BEGIN_SRC sml
  let val x0 = fn x => x in
     let val x1 = fn y => x0(x0(y)) in
        let val x2 = fn y => x1(x1(y)) in
           let val x3 = fn y => x2(x2(y)) in
           x3
        end
     end
  end
#+END_SRC

The extra `let`s bind `x2` to a function that composes `x1` twice, and
then `x3` to a function that composes `x2` twice. Hopefully you can
see where this is going: each time we add an extra nested `let`, we
double the number of times that `x0` is being composed. If you were to
transform the `let` expressions by hand, you'd end up with something
like:

#+BEGIN_SRC sml
  val x0 = fn x => x
  val x1 = fn y => x0(x0(y))
  val x2 = fn y => x0(x0(x0(x0(y))))
  val x3 = fn y => x0(x0(x0(x0(x0(x0(x0(x0(y))))))))
#+END_SRC

All of these functions behave the same way as the identity function,
but it's easy to imagine replacing `x0` with something more
interesting. And using the pattern above, you'd able to write a
program that concisely composes `x0` many times. The important point
is that when this program is changed by adding a single nested `let`,
its size grows linearly, but the number of compositions grows
exponentially (by doubling).

